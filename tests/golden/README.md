# TagTeam Golden Test Corpus

**Version:** 2.0
**Schema Version:** 2.0
**Created:** 2026-02-09
**Status:** Active Development

---

## ğŸ“– Overview

The **Golden Test Corpus** is a curated, versioned collection of reference test cases that define expected behavior for TagTeam's semantic parsing capabilities. Unlike unit tests (which test individual functions), golden tests validate **end-to-end parsing accuracy** against real-world scenarios.

### Purpose

1. **Regression Prevention** - Ensure new features don't break existing parsing
2. **Accuracy Benchmarking** - Track parsing accuracy improvements over time
3. **IEE Validation** - Verify compliance with IEE team requirements
4. **Documentation** - Serve as executable examples of expected behavior
5. **Version Stability** - Lock down v1 behavior before v2 architecture changes

---

## ğŸ“Š Current Status

| Metric | Value |
|--------|-------|
| **Total Corpuses** | 20 (1 complete, 19 planned) |
| **Total Test Cases** | 586 (20 complete, 566 planned) |
| **Completion** | 3.4% |
| **P0 Test Cases** | 396 |
| **Last Updated** | 2026-02-09 |

### By Category

| Category | Corpuses | Test Cases | Status |
|----------|----------|------------|--------|
| Phase-specific | 5 | 170 | â³ In Progress |
| Feature-specific | 5 | 110 | ğŸ“‹ Planned |
| v1-acceptance | 3 | 90 | ğŸ“‹ Planned |
| IEE-integration | 3 | 116 | ğŸ“‹ Planned |
| Regression | 3 | 60 | ğŸ“‹ Planned |
| Edge-cases | 1 | 40 | ğŸ“‹ Planned |

---

## ğŸ—‚ï¸ Corpus Structure

```
tests/golden/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ CONTRIBUTING.md                    # How to add test cases
â”œâ”€â”€ SCHEMA.md                          # Test case schema documentation
â”œâ”€â”€ corpus-index.json                  # Master index of all corpuses
â”‚
â”œâ”€â”€ schemas/                           # JSON schemas
â”‚   â””â”€â”€ test-case-schema-v2.json      # v2.0 test case schema
â”‚
â”œâ”€â”€ phase-specific/                    # Organized by roadmap phase
â”‚   â”œâ”€â”€ selectional-corpus.json        # âœ… Phase 6.0 - Complete (20 cases)
â”‚   â”œâ”€â”€ interpretation-lattice.json    # ğŸ“‹ Phase 6.1-6.4 - Planned (50 cases)
â”‚   â”œâ”€â”€ ontology-loading.json          # ğŸ“‹ Phase 6.5 - Planned (30 cases)
â”‚   â”œâ”€â”€ epistemic-markers.json         # ğŸ“‹ Phase 7.1-7.2 - Planned (40 cases)
â”‚   â””â”€â”€ validation-layer.json          # ğŸ“‹ Phase 9 - Planned (30 cases)
â”‚
â”œâ”€â”€ feature-specific/                  # Organized by linguistic feature
â”‚   â”œâ”€â”€ definiteness-corpus.json       # ğŸ“‹ Definite/indefinite NPs (20 cases)
â”‚   â”œâ”€â”€ modality-corpus.json           # ğŸ“‹ Deontic/epistemic modals (30 cases)
â”‚   â”œâ”€â”€ voice-corpus.json              # ğŸ“‹ Active/passive/middle (25 cases)
â”‚   â”œâ”€â”€ negation-corpus.json           # ğŸ“‹ Scope and polarity (20 cases)
â”‚   â””â”€â”€ temporal-corpus.json           # ğŸ“‹ Tense/aspect (15 cases)
â”‚
â”œâ”€â”€ v1-acceptance/                     # v1 scope contract validation
â”‚   â”œâ”€â”€ v1-core-features.json          # ğŸ“‹ All v1 IN SCOPE features (40 cases)
â”‚   â”œâ”€â”€ v1-deferred-features.json      # ğŸ“‹ All v1 EXPLICITLY DEFERRED (30 cases)
â”‚   â””â”€â”€ v1-edge-cases.json             # ğŸ“‹ Boundary conditions (20 cases)
â”‚
â”œâ”€â”€ iee-integration/                   # IEE team validation
â”‚   â”œâ”€â”€ ethical-values.json            # ğŸ“‹ Week 2b value detection (50 cases)
â”‚   â”œâ”€â”€ context-intensity.json         # ğŸ“‹ Week 2a dimensions (36 cases)
â”‚   â””â”€â”€ semantic-roles.json            # ğŸ“‹ Week 1 agent/patient (30 cases)
â”‚
â”œâ”€â”€ regression/                        # Historical regression tests
â”‚   â”œâ”€â”€ phase4-regressions.json        # ğŸ“‹ Phase 4 known issues (20 cases)
â”‚   â”œâ”€â”€ phase5-regressions.json        # ğŸ“‹ Phase 5 known issues (20 cases)
â”‚   â””â”€â”€ phase6-regressions.json        # ğŸ“‹ Phase 6 known issues (20 cases)
â”‚
â”œâ”€â”€ domain-specific/                   # Domain-specific tests
â”‚   â””â”€â”€ edge-cases.json                # ğŸ“‹ Comprehensive edge cases (40 cases)
â”‚
â””â”€â”€ results/                           # Test results and reports
    â”œâ”€â”€ latest-report.html             # HTML dashboard
    â”œâ”€â”€ accuracy-history.csv           # Historical tracking
    â””â”€â”€ latest-results.json            # Latest run results
```

---

## ğŸš€ Quick Start

### Running Golden Tests

```bash
# Run all golden tests
npm run test:golden

# Run specific corpus
npm run test:golden -- --corpus=selectional-corpus

# Run by priority
npm run test:golden -- --priority=P0

# Run by category
npm run test:golden -- --category=phase-specific

# Generate HTML report
npm run test:golden -- --report
```

### Adding a New Test Case

1. Choose the appropriate corpus file (see [CONTRIBUTING.md](CONTRIBUTING.md))
2. Follow the [test case schema v2.0](schemas/test-case-schema-v2.json)
3. Add your test case to the `cases` array
4. Validate schema: `npm run validate:golden`
5. Run tests: `npm run test:golden`
6. Update `corpus-index.json` with new test count

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed instructions.

---

## ğŸ“ Test Case Schema (v2.0)

### Minimal Example

```json
{
  "id": "lattice-001",
  "category": "deontic-epistemic-ambiguity",
  "input": "The doctor should prioritize the younger patient",
  "expectedOutput": {
    "defaultReading": {
      "modality": "obligation",
      "actualityStatus": "tagteam:Prescribed"
    },
    "alternativeReadings": [
      {
        "modality": "expectation",
        "actualityStatus": "tagteam:Hypothetical",
        "plausibility": 0.3
      }
    ],
    "ambiguityType": "modal_force",
    "ambiguityPreserved": true
  },
  "tags": ["modal", "deontic", "epistemic", "medical"],
  "priority": "P0"
}
```

### Full Schema

See [SCHEMA.md](SCHEMA.md) for complete schema documentation and examples.

---

## ğŸ“ˆ Success Criteria

### Target Metrics

| Metric | Target | Current | Status |
|--------|--------|---------|--------|
| Overall Accuracy | 95%+ | N/A | âŒ Not measured |
| P0 Pass Rate | 100% | N/A | âŒ Not measured |
| P1 Pass Rate | 95%+ | N/A | âŒ Not measured |
| P2 Pass Rate | 80%+ | N/A | âŒ Not measured |
| v1 Core Features | 100% | N/A | âŒ Not measured |
| IEE Value Detection | 75%+ | N/A | âŒ Not measured |

### Must-Have for v1 Release

- âœ… Interpretation lattice corpus (50 cases) passes at 95%+
- âœ… v1 core features corpus (40 cases) passes at 100%
- âœ… IEE value detection corpus (50 cases) passes at 75%+
- âœ… Automated test runner integrated into CI/CD
- âœ… No regressions in existing selectional-corpus.json

---

## ğŸ” Corpus Index

For a complete list of all corpuses, see [corpus-index.json](corpus-index.json).

### By Priority

| Priority | Corpuses | Test Cases | Description |
|----------|----------|------------|-------------|
| **P0** | 12 | 396 | Critical - blocking v1 release |
| **P1** | 7 | 150 | High - should have for v1 |
| **P2** | 1 | 40 | Medium - nice to have |

### By Phase

| Phase | Corpuses | Test Cases | Status |
|-------|----------|------------|--------|
| Phase 6 | 4 | 150 | â³ In Progress |
| Phase 7 | 1 | 40 | ğŸ“‹ Planned |
| v1 | 8 | 235 | ğŸ“‹ Planned |
| IEE | 3 | 116 | ğŸ“‹ Planned |
| Regression | 3 | 60 | ğŸ“‹ Planned |

---

## ğŸ› ï¸ Test Runner

The golden test runner (`run-golden-tests.js`) provides:

- âœ… **Schema Validation** - Validates test cases against v2.0 schema
- âœ… **Result Comparison** - Compares expected vs actual output
- âœ… **Diff Reporting** - Human-readable differences
- âœ… **Metrics Tracking** - Accuracy, pass rate, coverage
- âœ… **Filtering** - By corpus, priority, category, tags
- âœ… **HTML Reports** - Visual dashboard with charts
- âœ… **CI/CD Integration** - GitHub Actions support
- âœ… **Regression Detection** - Compares with previous run

### Usage Examples

```bash
# Basic run
npm run test:golden

# Verbose output
npm run test:golden -- --verbose

# Watch mode (re-run on file changes)
npm run test:golden -- --watch

# Update snapshots (careful!)
npm run test:golden -- --update-snapshots

# Dry run (validate without executing)
npm run test:golden -- --dry-run
```

---

## ğŸ“š Documentation

- **[CONTRIBUTING.md](CONTRIBUTING.md)** - How to add test cases
- **[SCHEMA.md](SCHEMA.md)** - Test case schema documentation
- **[corpus-index.json](corpus-index.json)** - Master corpus index
- **[GOLDEN_TEST_CORPUS_PLAN.md](../../planning/GOLDEN_TEST_CORPUS_PLAN.md)** - Implementation plan
- **[ROADMAP.md](../../ROADMAP.md)** - Project roadmap

---

## ğŸ”— Related Resources

- **IEE Collaboration**: [iee-collaboration/](../../iee-collaboration/)
- **Unit Tests**: [tests/unit/](../unit/)
- **Integration Tests**: [tests/integration/](../integration/)
- **Deliverables**: [deliverables/](../../deliverables/)

---

## ğŸ“ Version History

| Version | Date | Changes |
|---------|------|---------|
| 2.0 | 2026-02-09 | Initial golden test corpus infrastructure |
| 1.0 | 2026-01-26 | Selectional corpus (Phase 6.0) |

---

## ğŸ¤ Contributing

We welcome contributions to the golden test corpus! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for:

- How to choose the right corpus file
- Test case authoring guidelines
- Schema validation requirements
- Pull request process
- Code review checklist

---

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/anthropics/claude-code/issues)
- **Documentation**: [docs/](../../docs/)
- **IEE Team**: See [iee-collaboration/](../../iee-collaboration/)

---

*Golden Test Corpus - TagTeam.js v3.0*
*Built with â¤ï¸ by the TagTeam Core Team*
